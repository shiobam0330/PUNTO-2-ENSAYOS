{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1f0863879114843be9a6edefb5aad04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2cd3784c40742769a113fa50f3419a9",
              "IPY_MODEL_0ed91395456a41e2a03038d5aa42468a",
              "IPY_MODEL_b1b89dacb85e4d429485aff8ce653bd2"
            ],
            "layout": "IPY_MODEL_022172ac05f74ef8ad5a72494d76234e"
          }
        },
        "c2cd3784c40742769a113fa50f3419a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8198556000ac4f6195109486d194cf48",
            "placeholder": "​",
            "style": "IPY_MODEL_60e63c46c3494e0b8c90e6a80989382f",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "0ed91395456a41e2a03038d5aa42468a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4254b277e04211ba82c3ce9329b704",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3f41b2b4a5c4ec69f262f1fc6c6dbfd",
            "value": 48453
          }
        },
        "b1b89dacb85e4d429485aff8ce653bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a73d2b27af047b49cc5dda4aa6e9e75",
            "placeholder": "​",
            "style": "IPY_MODEL_2bff280eac3c4ac7987d2cc43e50f1c2",
            "value": " 392k/? [00:00&lt;00:00, 4.67MB/s]"
          }
        },
        "022172ac05f74ef8ad5a72494d76234e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8198556000ac4f6195109486d194cf48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e63c46c3494e0b8c90e6a80989382f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b4254b277e04211ba82c3ce9329b704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f41b2b4a5c4ec69f262f1fc6c6dbfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a73d2b27af047b49cc5dda4aa6e9e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bff280eac3c4ac7987d2cc43e50f1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tl6H5tBjtjQ",
        "outputId": "5ccd0541-d24a-4f74-bfe6-f19f62a38209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.6)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.14.0 stanza-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTSkPn8LkCCD",
        "outputId": "95c7567f-6032-472d-f342-a694b2253442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kneed\n",
            "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.13.1)\n",
            "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: kneed\n",
            "Successfully installed kneed-0.8.5\n"
          ]
        }
      ],
      "source": [
        "!pip install kneed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISIBmaMVkH_8",
        "outputId": "b1ce64d0-5ec9-4a9f-cd4d-097fe8a3b090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plot_metric\n",
            "  Downloading plot_metric-0.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (3.8.0)\n",
            "Requirement already satisfied: colorlover>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (0.3.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from plot_metric) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.2->plot_metric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->plot_metric) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->plot_metric) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->plot_metric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->plot_metric) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.2->plot_metric) (1.16.0)\n",
            "Downloading plot_metric-0.0.6-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: plot_metric\n",
            "Successfully installed plot_metric-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install plot_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIJtic5q5JOp",
        "outputId": "18081abc-c56f-459f-9b43-e66ee6b65c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download 'en_core_web_lg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK9hX7g6y7q5",
        "outputId": "c0224e6c-268a-496f-ff99-c0c53382256c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (4.66.6)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (2024.8.30)\n",
            "Downloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: language_tool_python\n",
            "Successfully installed language_tool_python-2.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install language_tool_python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJq3cefOzMUO",
        "outputId": "515f019b-b1b4-4a71-b017-c8341adfb52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296186 sha256=43da13275bbba81a0299b2aaae4ae6c485250a70c3b441504aede4890832bf39\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Mx2xEfyoXK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import language_tool_python\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import fasttext ## embedings\n",
        "from spacy.lang.es.stop_words import STOP_WORDS\n",
        "from sklearn.decomposition import PCA\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import stanza\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import en_core_web_lg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "from pprint import pprint\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from wordcloud import WordCloud\n",
        "import spacy\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ehSvNpVf21",
        "outputId": "68d12f4e-f304-4782-8fab-8a67b1bd10b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_datos():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    path = \"/content/drive/MyDrive/bases/\"\n",
        "    archivo_tsv = \"training_set_rel3.tsv\"\n",
        "    df = pd.read_csv(path + archivo_tsv, delimiter='\\t', encoding='latin1')\n",
        "    datos=  pd.read_pickle(path + 'training_features_NLP_Ensayos.pkl')\n",
        "\n",
        "    return datos, path,df\n"
      ],
      "metadata": {
        "id": "x3NrByHXRVxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparacion_datos(datos, path):\n",
        "  datos = datos.get([\"essay_id\",\"corrected\",\"tokens\",\"essay_set\",\n",
        "           \"corrections\",\"token_count\",\"unique_token_count\",\n",
        "           \"nostop_count\",\"sent_count\",\"ner_count\",\"comma\",\"question\",\n",
        "           \"exclamation\", \"quotation\", \"organization\", \"caps\", \"person\",\n",
        "           \"location\", \"money\", \"time\", \"date\", \"percent\", \"noun\", \"adj\", \"pron\",\n",
        "           \"verb\", \"cconj\", \"adv\", \"det\", \"propn\", \"num\", \"part\", \"intj\"])\n",
        "  datos = datos.rename(columns = {'corrected':'essay'})\n",
        "  datos = datos.drop(columns=['essay_set'])\n",
        "  datos['essay'].to_csv(path + 'ensayos_NLP_Ensayos.csv')\n",
        "  return datos\n"
      ],
      "metadata": {
        "id": "h_3EosLfSjaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELO LDA"
      ],
      "metadata": {
        "id": "BdOKvxs3VFaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_stemming(text):\n",
        "    ps = PorterStemmer()\n",
        "    return ps.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text): #  gensim.utils.simple_preprocess tokeniza el texto\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "metadata": {
        "id": "_Qbd94xFXlxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelo_LDA(datos, path):\n",
        "  data = datos.get(['essay','essay_id'])\n",
        "  nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
        "  stop_nltk = stopwords.words('english')\n",
        "  nlp = en_core_web_lg.load()\n",
        "  stop_spacy = nlp.Defaults.stop_words\n",
        "  stop_todas = list(stop_spacy.union(set(stop_nltk)))\n",
        "  data=  pd.read_pickle(path + 'training_procesed_text.pkl')\n",
        "  data[\"essay\"] = data[\"processed_text\"].copy()\n",
        "  data = data.drop([\"processed_text\"],axis = 1)\n",
        "  documents = data\n",
        "  doc_sample = documents[documents['essay_id'] == 10].values[0][0]\n",
        "  words = []\n",
        "  for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "  processed_docs = documents['essay'].map(preprocess)\n",
        "  dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "  count = 0\n",
        "  for k, v in dictionary.iteritems():\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break\n",
        "  dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=500)\n",
        "  bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "  tfidf = models.TfidfModel(bow_corpus)\n",
        "  corpus_tfidf = tfidf[bow_corpus]\n",
        "  return dictionary, bow_corpus, tfidf, corpus_tfidf,documents,data\n"
      ],
      "metadata": {
        "id": "ASZyc9l9VEvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LDA_wo(bow_corpus, data,dictionary):\n",
        "  lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=8, id2word=dictionary, passes=2, workers=2)\n",
        "  ind_without_tfidf = lda_model[bow_corpus]\n",
        "  topics_wo = []\n",
        "  for y in range(data.shape[0]):\n",
        "    if len(ind_without_tfidf[y]) > 0:\n",
        "      valid_sublist = [sublist for sublist in ind_without_tfidf[y] if len(sublist) > 1]\n",
        "      if len(valid_sublist) > 0:\n",
        "        max_index = np.argmax([sublist[1] for sublist in valid_sublist])\n",
        "        topics_wo.append(valid_sublist[max_index][0])\n",
        "      else:\n",
        "        topics_wo.append(None)\n",
        "    else:\n",
        "      topics_wo.append(None)\n",
        "  data[\"topic\"] = topics_wo\n",
        "  return data"
      ],
      "metadata": {
        "id": "O8DZp_WzahFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LDA_TFIDF(tfidf, data,dictionary,corpus_tfidf, bow_corpus):\n",
        "  lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=8, id2word=dictionary, passes=2, workers=4)\n",
        "  ind_with_tfidf = lda_model_tfidf[bow_corpus]\n",
        "  topics_with = []\n",
        "  for y in range(data.shape[0]):\n",
        "    if len(ind_with_tfidf[y]) > 0:\n",
        "      valid_sublist = [sublist for sublist in ind_with_tfidf[y] if len(sublist) > 1]\n",
        "      if len(valid_sublist) > 0:\n",
        "        max_index = np.argmax([sublist[1] for sublist in valid_sublist])\n",
        "        topics_with.append(valid_sublist[max_index][0])\n",
        "      else:\n",
        "        topics_with.append(None)\n",
        "    else:\n",
        "      topics_with.append(None)\n",
        "  data[\"topic_tfidf\"] = topics_with\n",
        "  data_LDA = data.copy()\n",
        "  return data_LDA"
      ],
      "metadata": {
        "id": "j8UxPLbmeEwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddings(path):\n",
        "  data=  pd.read_pickle(path + 'training_procesed_text_embeddings_finaaaall.pkl')\n",
        "  embeddings = np.stack(data['bert_embedding'].values)\n",
        "  pca = PCA(n_components=2)\n",
        "  embeddings_pca = pca.fit_transform(embeddings)\n",
        "  df_pca = pd.DataFrame(embeddings_pca, columns=['x', 'y'])\n",
        "  n_max = 10  # Puedes ajustar este valor según lo necesites\n",
        "  silhouette_coefficients = []\n",
        "  scaler = StandardScaler()\n",
        "  scaled_pcs = scaler.fit_transform(embeddings_pca)\n",
        "  for k in range(2, n_max + 1):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    kmeans.fit(scaled_pcs)\n",
        "    score = silhouette_score(scaled_pcs, kmeans.labels_)\n",
        "    silhouette_coefficients.append(score)\n",
        "  kmeans = KMeans(n_clusters=8, random_state=0).fit(embeddings)\n",
        "  data['cluster'] = kmeans.labels_\n",
        "  return data, n_max\n"
      ],
      "metadata": {
        "id": "NOIfIsahgGmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_text(path,data):\n",
        "  doc_embedding = pd.read_csv(path + 'Doc_Embedding_300_NLP_Ensayos.csv',index_col=0)\n",
        "  pca = PCA(n_components=30, random_state=0)\n",
        "  pcs = pca.fit_transform(doc_embedding.values)\n",
        "  scaler = StandardScaler()\n",
        "  scaled_pcs = scaler.fit_transform(pcs)\n",
        "  silhouette_coefficients = []\n",
        "  kmeans_kwargs = {\"init\": \"random\",\"n_init\": 10,\"max_iter\": 300,\"random_state\": 42}\n",
        "  for k in range(2, n_max):\n",
        "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "    kmeans.fit(scaled_pcs)\n",
        "    score = silhouette_score(scaled_pcs, kmeans.labels_)\n",
        "    silhouette_coefficients.append(score)\n",
        "  K_ = 8\n",
        "  km = KMeans(n_clusters=K_, random_state=0)\n",
        "  km.fit_transform(scaled_pcs)\n",
        "  cluster_labels = km.labels_\n",
        "  cluster_labels = pd.DataFrame(cluster_labels, columns=['Grupo'])\n",
        "  data[\"FAST\"] = km.labels_\n",
        "  return data"
      ],
      "metadata": {
        "id": "sQI9ZC5AiseI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compar_models(data,data_LDA,df):\n",
        "  data = data.drop([\"Unnamed: 0\"],axis = 1)\n",
        "  data[\"essay_id\"] = data_LDA[\"essay_id\"].copy()\n",
        "  data_LDA = data_LDA.drop([\"essay\"],axis = 1)\n",
        "  data = pd.merge(data,data_LDA,on = [\"essay_id\"], how = \"left\")\n",
        "  data[\"essay_set\"] = df[\"essay_set\"].copy()\n",
        "  crosstabb =pd.crosstab(data[\"essay_set\"],data[\"topic_tfidf\"])\n",
        "  crosstab1 = pd.crosstab(data[\"essay_set\"],data[\"topic\"])\n",
        "  crosstab2 = pd.crosstab(data[\"essay_set\"],data[\"FAST\"])\n",
        "  crosstab3 = pd.crosstab(data[\"essay_set\"],data[\"cluster\"])\n",
        "  return crosstabb,crosstab1,crosstab2,crosstab3,data"
      ],
      "metadata": {
        "id": "mwscqjp1kEbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reorganizar_matriz(crosstab):\n",
        "    crosstab = crosstab.apply(pd.to_numeric, errors='coerce')\n",
        "    available_cols = list(crosstab.columns)\n",
        "    row_order = []\n",
        "    col_order = []\n",
        "\n",
        "    for row in crosstab.index:\n",
        "        max_col = crosstab.loc[row, available_cols].idxmax()\n",
        "        row_order.append(row)\n",
        "        col_order.append(max_col)\n",
        "        available_cols.remove(max_col)\n",
        "\n",
        "    crosstab_sorted = crosstab.loc[row_order, col_order]\n",
        "    matriz = crosstab_sorted.values\n",
        "    return matriz"
      ],
      "metadata": {
        "id": "B6_V7xZLlCuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_accuracy(matriz):\n",
        "    return np.diag(matriz).sum() * 100 / np.sum(matriz)"
      ],
      "metadata": {
        "id": "Lewda_VfI2wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_global(data_con_fast, data_con_tema_tfidf, df):\n",
        "    crosstabb, crosstab1, crosstab2, crosstab3, data_comparada = compar_models(data_con_fast, data_con_tema_tfidf, df)\n",
        "    matrices = [crosstabb, crosstab1, crosstab2, crosstab3]\n",
        "    matrices_reorganizadas = [reorganizar_matriz(mat) for mat in matrices]\n",
        "    accuracies = [calcular_accuracy(mat) for mat in matrices_reorganizadas]\n",
        "\n",
        "    ac_tfidf, ac_topic, ac_fast, ac_bert = accuracies\n",
        "\n",
        "    print(f\"Accuracy TF-IDF: {ac_tfidf}%\")\n",
        "    print(f\"Accuracy Topic: {ac_topic}%\")\n",
        "    print(f\"Accuracy Fast: {ac_fast}%\")\n",
        "    print(f\"Accuracy BERT: {ac_bert}%\")\n",
        "    return ac_tfidf, ac_topic, ac_fast, ac_bert, data_comparada"
      ],
      "metadata": {
        "id": "0Zo6mvAwI6iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tabla_roc_scores(path,data):\n",
        "  resultados_roc = {}\n",
        "  columnas = ['cluster', 'topic', 'topic_tfidf', 'FAST']\n",
        "  for col in columnas:\n",
        "    roc_scores = []\n",
        "    for Clase in range(1, 9):\n",
        "      prediccion = Clase - 1\n",
        "      data_final_copia = data.copy()\n",
        "      data_final_copia.loc[data_final_copia[\"essay_set\"] != Clase, \"essay_set\"] = -1\n",
        "      data_final_copia.loc[data_final_copia[\"essay_set\"] == Clase, \"essay_set\"] = 1\n",
        "      data_final_copia.loc[data_final_copia[\"essay_set\"] == -1, \"essay_set\"] = 0\n",
        "\n",
        "      data_final_copia.loc[data_final_copia[col] != prediccion, col] = -1\n",
        "      data_final_copia.loc[data_final_copia[col] == prediccion, col] = 1\n",
        "      data_final_copia.loc[data_final_copia[col] == -1, col] = 0\n",
        "\n",
        "      ytrue = list(data_final_copia[\"essay_set\"])\n",
        "      yest = list(data_final_copia[col])\n",
        "      roc_score = roc_auc_score(ytrue, yest)\n",
        "      roc_scores.append(roc_score)\n",
        "    resultados_roc[col] = roc_scores\n",
        "  resultados_df = pd.DataFrame(resultados_roc, index=range(1, 9))\n",
        "  resultados_df.index.name = 'essay_set'\n",
        "  resultados_df.to_csv(path + 'roc_scores.csv')\n",
        "  return resultados_df"
      ],
      "metadata": {
        "id": "4n-YZP9mly1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RED NEURONAL"
      ],
      "metadata": {
        "id": "6Q2g0X3x5d1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, SpatialDropout1D, Bidirectional, GRU, Input,Concatenate\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score"
      ],
      "metadata": {
        "id": "ipQlq6FLC_sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inic_red(path):\n",
        "  doc_embedding = pd.read_csv(path + 'Doc_Embedding_300_NLP_Ensayos.csv',index_col=0)\n",
        "  datos=  pd.read_pickle(path + 'training_red_neuronal.pkl')\n",
        "  X_provisional = datos.get([\"corrections\",\"token_count\"]) # dos variables al azar\n",
        "  y_provisional = datos.get([\"essay_set\"]).to_numpy()\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_provisional,y_provisional,test_size = 0.10,stratify = y_provisional)\n",
        "  index_train = X_train.index\n",
        "  index_test = X_test.index\n",
        "  features = [x for x in datos.columns if x not in [\"essay_set\",\"essay\",\"tokens\",\"essay_id\"]]\n",
        "  X = datos.get(features).copy()\n",
        "  y = datos.get([\"essay_set\"]).copy()\n",
        "  return index_train, index_test, X, y, X_train, X_test, y_train, y_test,doc_embedding"
      ],
      "metadata": {
        "id": "2165tMPHZANX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proc_red(X_train, X_test, y_train, y_test,index_train,index_test,doc_embedding,X,y):\n",
        "  features_train = X.iloc[index_train,]\n",
        "  embeddings_train = doc_embedding.iloc[index_train,]\n",
        "  y_train = y.iloc[index_train,] # supervisada\n",
        "\n",
        "  # Test\n",
        "  features_test = X.iloc[index_test,]\n",
        "  embeddings_test = doc_embedding.iloc[index_test,]\n",
        "  y_test = y.iloc[index_test,] # supervisada\n",
        "\n",
        "  y_train = y_train - 1\n",
        "  y_test = y_test - 1\n",
        "  return features_train, embeddings_train, y_train, features_test, embeddings_test, y_test"
      ],
      "metadata": {
        "id": "wO6AJVYCZAJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estandariza(features_train,features_test):\n",
        "  scaler = MinMaxScaler((-1.0,1.0))\n",
        "  features_train_scaled = pd.DataFrame(scaler.fit_transform(features_train))\n",
        "  features_train_scaled.columns = features_train.columns\n",
        "  features_test_scaled = pd.DataFrame(scaler.fit_transform(features_test))\n",
        "  features_test_scaled.columns = features_test.columns\n",
        "  return features_train_scaled, features_test_scaled"
      ],
      "metadata": {
        "id": "H14KxX51ZAGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capas(features_train_scaled):\n",
        "  embedding_vector_length = 300\n",
        "\n",
        "  x1 = Input(shape=(embedding_vector_length,), name='Input_Embedding')\n",
        "  x2 = Input(shape=(features_train_scaled.shape[1],), name='Input_Features')\n",
        "\n",
        "  # Capa entrada\n",
        "  x = Concatenate(name='Concatenar')([x1, x2])\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  # capas ocultas\n",
        "  x = Dense(64, activation='elu', name='Capa_Densa_1')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = Dense(32, activation='elu', name='Capa_Densa_2')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = Dense(16, activation='elu', name='Capa_Densa_3')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  # Capa de salida para clasificación binaria\n",
        "  x = Dense(8, activation='softmax', name='Output')(x)\n",
        "\n",
        "  model = Model(inputs=[x1, x2], outputs=x)\n",
        "\n",
        "  # Compilación para clasificación binaria\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "rKTl92ewZACf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def red_neuronal(embeddings_train,features_train_scaled,y_train,embeddings_test,features_test_scaled,y_test,model):\n",
        "  history = model.fit(x = [embeddings_train,features_train_scaled],\n",
        "                    y = y_train,\n",
        "                    validation_data = ([embeddings_test,features_test_scaled],y_test),\n",
        "                    epochs=100,\n",
        "                    batch_size=32,verbose=1)\n",
        "  return history"
      ],
      "metadata": {
        "id": "fppV5jlrY_-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_train(embeddings_train,features_train_scaled,y_train,model):\n",
        "  y_pred = model.predict([embeddings_train,features_train_scaled])\n",
        "  y_true = y_train\n",
        "  y_pred = (y_pred >= 0.5).astype(int)\n",
        "  y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "  accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "v9eOxXgkY_7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_test(embeddings_test,features_test_scaled,y_test,model):\n",
        "  y_pred = model.predict([embeddings_test,features_test_scaled])\n",
        "  y_true = y_test\n",
        "  y_pred = (y_pred>=0.5).astype(int)\n",
        "  y_pred_classes1 = np.argmax(y_pred, axis=1)\n",
        "  accuracy1 = accuracy_score(y_true, y_pred_classes1)\n",
        "  return accuracy1"
      ],
      "metadata": {
        "id": "0LB5QcaLY_3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ejecutar(path, embeddings_train, features_train_scaled, y_train,\n",
        "                               embeddings_test, features_test_scaled, y_test, model):\n",
        "    history = red_neuronal(embeddings_train, features_train_scaled, y_train,\n",
        "                           embeddings_test, features_test_scaled, y_test, model)\n",
        "    accuracy_train = pred_train(embeddings_train, features_train_scaled, y_train, model)\n",
        "    accuracy_test = pred_test(embeddings_test, features_test_scaled, y_test, model)\n",
        "    print(f\"Accuracy en entrenamiento: {accuracy_train * 100:.2f}%\")\n",
        "    print(f\"Accuracy en prueba: {accuracy_test * 100:.2f}%\")\n",
        "    return accuracy_train, accuracy_test, history\n"
      ],
      "metadata": {
        "id": "FEhsb12uY_rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cargar_y_preparar_datos():\n",
        "    datos,path, df = cargar_datos()\n",
        "    datos_procesados = preparacion_datos(datos, path)\n",
        "    return datos_procesados, path,df\n",
        "def crear_modelo_LDA(datos_procesados, path):\n",
        "    dictionary, bow_corpus, tfidf, corpus_tfidf, documents, data = modelo_LDA(datos_procesados, path)\n",
        "    data_con_tema_wo = LDA_wo(bow_corpus, data, dictionary)\n",
        "    data_con_tema_tfidf = LDA_TFIDF(tfidf, data, dictionary, corpus_tfidf, bow_corpus)\n",
        "    return data_con_tema_wo, data_con_tema_tfidf, data\n",
        "def integrar_embeddings_y_modelos(path, data):\n",
        "    data_con_embeddings, n_max = embeddings(path)\n",
        "    data_con_fast = fast_text(path, data_con_embeddings)\n",
        "    return data_con_fast\n",
        "def comparar_modelos_y_calcular_accuracy(data_con_fast, data_con_tema_tfidf, df):\n",
        "    crosstabb, crosstab1, crosstab2, crosstab3, data_comparada = compar_models(data_con_fast, data_con_tema_tfidf, df)\n",
        "    ac_tfidf, ac_topic, ac_fast, ac_bert, data_comparada = accuracy_global(data_con_fast, data_con_tema_tfidf, df)\n",
        "    return data_comparada\n",
        "def generar_tabla_roc(path, data_comparada):\n",
        "    resultados_roc = tabla_roc_scores(path, data_comparada)\n",
        "    return resultados_roc"
      ],
      "metadata": {
        "id": "AwGLlu0PUl-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parte1(path):\n",
        "    datos_procesados, path, df = cargar_y_preparar_datos()\n",
        "    data_con_tema_wo, data_con_tema_tfidf, data = crear_modelo_LDA(datos_procesados, path)\n",
        "    data_con_fast = integrar_embeddings_y_modelos(path, data)\n",
        "    data_comparada = comparar_modelos_y_calcular_accuracy(data_con_fast, data_con_tema_tfidf, df)\n",
        "    resultados_roc = generar_tabla_roc(path, data_comparada)\n",
        "    print(resultados_roc)\n",
        "    return resultados_roc"
      ],
      "metadata": {
        "id": "2NO75OwsZGz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar_ejecutar_red_neuronal(path, data):\n",
        "    datos_procesados, path, df = cargar_y_preparar_datos()\n",
        "    index_train, index_test, X, y, X_train, X_test, y_train, y_test, doc_embedding = inic_red(path)\n",
        "    features_train, embeddings_train, y_train, features_test, embeddings_test, y_test = proc_red(\n",
        "    X_train, X_test, y_train, y_test, index_train, index_test, doc_embedding, X, y)\n",
        "    features_train_scaled, features_test_scaled = estandariza(features_train, features_test)\n",
        "    model = capas(features_train_scaled)\n",
        "    accuracy_train, accuracy_test, history = ejecutar(\n",
        "        path, embeddings_train, features_train_scaled, y_train,\n",
        "        embeddings_test, features_test_scaled, y_test, model, data)\n",
        "    return accuracy_train, accuracy_test, history\n"
      ],
      "metadata": {
        "id": "aJ4SP_DvYizH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train, accuracy_test, history = preparar_ejecutar_red_neuronal(path, data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTvGK0A0Ytz8",
        "outputId": "65b1db18-fcca-4fd4-a266-70c8fb86f24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4552 - loss: 1.5047 - val_accuracy: 0.9700 - val_loss: 0.1836\n",
            "Epoch 2/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.3524 - val_accuracy: 0.9823 - val_loss: 0.0828\n",
            "Epoch 3/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.2379 - val_accuracy: 0.9861 - val_loss: 0.0664\n",
            "Epoch 4/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9425 - loss: 0.1908 - val_accuracy: 0.9869 - val_loss: 0.0619\n",
            "Epoch 5/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.1644 - val_accuracy: 0.9861 - val_loss: 0.0597\n",
            "Epoch 6/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1596 - val_accuracy: 0.9838 - val_loss: 0.0588\n",
            "Epoch 7/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.1625 - val_accuracy: 0.9869 - val_loss: 0.0492\n",
            "Epoch 8/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1313 - val_accuracy: 0.9884 - val_loss: 0.0510\n",
            "Epoch 9/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1231 - val_accuracy: 0.9892 - val_loss: 0.0501\n",
            "Epoch 10/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1232 - val_accuracy: 0.9884 - val_loss: 0.0495\n",
            "Epoch 11/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.1395 - val_accuracy: 0.9869 - val_loss: 0.0582\n",
            "Epoch 12/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1106 - val_accuracy: 0.9892 - val_loss: 0.0475\n",
            "Epoch 13/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.1047 - val_accuracy: 0.9900 - val_loss: 0.0440\n",
            "Epoch 14/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0948 - val_accuracy: 0.9892 - val_loss: 0.0561\n",
            "Epoch 15/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0988 - val_accuracy: 0.9861 - val_loss: 0.0588\n",
            "Epoch 16/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.1084 - val_accuracy: 0.9884 - val_loss: 0.0556\n",
            "Epoch 17/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.1075 - val_accuracy: 0.9908 - val_loss: 0.0495\n",
            "Epoch 18/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.1038 - val_accuracy: 0.9892 - val_loss: 0.0417\n",
            "Epoch 19/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9751 - loss: 0.0928 - val_accuracy: 0.9900 - val_loss: 0.0426\n",
            "Epoch 20/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9706 - loss: 0.0964 - val_accuracy: 0.9908 - val_loss: 0.0460\n",
            "Epoch 21/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0814 - val_accuracy: 0.9938 - val_loss: 0.0428\n",
            "Epoch 22/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0856 - val_accuracy: 0.9900 - val_loss: 0.0449\n",
            "Epoch 23/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0860 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
            "Epoch 24/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0778 - val_accuracy: 0.9915 - val_loss: 0.0426\n",
            "Epoch 25/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.0848 - val_accuracy: 0.9908 - val_loss: 0.0377\n",
            "Epoch 26/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0773 - val_accuracy: 0.9900 - val_loss: 0.0453\n",
            "Epoch 27/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0735 - val_accuracy: 0.9892 - val_loss: 0.0458\n",
            "Epoch 28/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9746 - loss: 0.0899 - val_accuracy: 0.9908 - val_loss: 0.0398\n",
            "Epoch 29/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0905 - val_accuracy: 0.9892 - val_loss: 0.0452\n",
            "Epoch 30/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0759 - val_accuracy: 0.9892 - val_loss: 0.0415\n",
            "Epoch 31/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0812 - val_accuracy: 0.9900 - val_loss: 0.0410\n",
            "Epoch 32/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0756 - val_accuracy: 0.9900 - val_loss: 0.0387\n",
            "Epoch 33/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0764 - val_accuracy: 0.9900 - val_loss: 0.0365\n",
            "Epoch 34/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9784 - loss: 0.0757 - val_accuracy: 0.9884 - val_loss: 0.0555\n",
            "Epoch 35/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0806 - val_accuracy: 0.9892 - val_loss: 0.0394\n",
            "Epoch 36/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0851 - val_accuracy: 0.9900 - val_loss: 0.0368\n",
            "Epoch 37/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0749 - val_accuracy: 0.9900 - val_loss: 0.0419\n",
            "Epoch 38/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0742 - val_accuracy: 0.9884 - val_loss: 0.0484\n",
            "Epoch 39/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0770 - val_accuracy: 0.9908 - val_loss: 0.0393\n",
            "Epoch 40/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0626 - val_accuracy: 0.9900 - val_loss: 0.0443\n",
            "Epoch 41/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0713 - val_accuracy: 0.9908 - val_loss: 0.0446\n",
            "Epoch 42/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0722 - val_accuracy: 0.9908 - val_loss: 0.0364\n",
            "Epoch 43/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0590 - val_accuracy: 0.9900 - val_loss: 0.0362\n",
            "Epoch 44/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0609 - val_accuracy: 0.9900 - val_loss: 0.0386\n",
            "Epoch 45/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0674 - val_accuracy: 0.9892 - val_loss: 0.0348\n",
            "Epoch 46/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0621 - val_accuracy: 0.9892 - val_loss: 0.0480\n",
            "Epoch 47/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0699 - val_accuracy: 0.9908 - val_loss: 0.0415\n",
            "Epoch 48/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0654 - val_accuracy: 0.9908 - val_loss: 0.0463\n",
            "Epoch 49/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0643 - val_accuracy: 0.9908 - val_loss: 0.0478\n",
            "Epoch 50/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0702 - val_accuracy: 0.9931 - val_loss: 0.0379\n",
            "Epoch 51/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.0608 - val_accuracy: 0.9900 - val_loss: 0.0413\n",
            "Epoch 52/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0708 - val_accuracy: 0.9900 - val_loss: 0.0410\n",
            "Epoch 53/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0641 - val_accuracy: 0.9908 - val_loss: 0.0565\n",
            "Epoch 54/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0666 - val_accuracy: 0.9915 - val_loss: 0.0433\n",
            "Epoch 55/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0639 - val_accuracy: 0.9900 - val_loss: 0.0420\n",
            "Epoch 56/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0716 - val_accuracy: 0.9884 - val_loss: 0.0420\n",
            "Epoch 57/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0678 - val_accuracy: 0.9915 - val_loss: 0.0349\n",
            "Epoch 58/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0608 - val_accuracy: 0.9900 - val_loss: 0.0420\n",
            "Epoch 59/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0653 - val_accuracy: 0.9900 - val_loss: 0.0394\n",
            "Epoch 60/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0667 - val_accuracy: 0.9908 - val_loss: 0.0414\n",
            "Epoch 61/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0698 - val_accuracy: 0.9892 - val_loss: 0.0416\n",
            "Epoch 62/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0681 - val_accuracy: 0.9892 - val_loss: 0.0446\n",
            "Epoch 63/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0592 - val_accuracy: 0.9908 - val_loss: 0.0468\n",
            "Epoch 64/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0617 - val_accuracy: 0.9892 - val_loss: 0.0427\n",
            "Epoch 65/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0666 - val_accuracy: 0.9900 - val_loss: 0.0390\n",
            "Epoch 66/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0583 - val_accuracy: 0.9900 - val_loss: 0.0401\n",
            "Epoch 67/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0614 - val_accuracy: 0.9915 - val_loss: 0.0457\n",
            "Epoch 68/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0811 - val_accuracy: 0.9908 - val_loss: 0.0455\n",
            "Epoch 69/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.0655 - val_accuracy: 0.9923 - val_loss: 0.0453\n",
            "Epoch 70/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0647 - val_accuracy: 0.9900 - val_loss: 0.0407\n",
            "Epoch 71/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0527 - val_accuracy: 0.9892 - val_loss: 0.0486\n",
            "Epoch 72/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0591 - val_accuracy: 0.9915 - val_loss: 0.0481\n",
            "Epoch 73/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0561 - val_accuracy: 0.9915 - val_loss: 0.0402\n",
            "Epoch 74/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0644 - val_accuracy: 0.9908 - val_loss: 0.0430\n",
            "Epoch 75/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0632 - val_accuracy: 0.9908 - val_loss: 0.0387\n",
            "Epoch 76/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0648 - val_accuracy: 0.9892 - val_loss: 0.0403\n",
            "Epoch 77/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0669 - val_accuracy: 0.9923 - val_loss: 0.0364\n",
            "Epoch 78/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0670 - val_accuracy: 0.9915 - val_loss: 0.0390\n",
            "Epoch 79/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0757 - val_accuracy: 0.9923 - val_loss: 0.0417\n",
            "Epoch 80/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0610 - val_accuracy: 0.9915 - val_loss: 0.0436\n",
            "Epoch 81/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0671 - val_accuracy: 0.9892 - val_loss: 0.0421\n",
            "Epoch 82/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0520 - val_accuracy: 0.9908 - val_loss: 0.0378\n",
            "Epoch 83/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0593 - val_accuracy: 0.9877 - val_loss: 0.0445\n",
            "Epoch 84/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0518 - val_accuracy: 0.9892 - val_loss: 0.0394\n",
            "Epoch 85/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0665 - val_accuracy: 0.9908 - val_loss: 0.0411\n",
            "Epoch 86/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0583 - val_accuracy: 0.9938 - val_loss: 0.0370\n",
            "Epoch 87/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0593 - val_accuracy: 0.9908 - val_loss: 0.0441\n",
            "Epoch 88/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0545 - val_accuracy: 0.9931 - val_loss: 0.0400\n",
            "Epoch 89/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0638 - val_accuracy: 0.9923 - val_loss: 0.0400\n",
            "Epoch 90/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0583 - val_accuracy: 0.9900 - val_loss: 0.0410\n",
            "Epoch 91/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0646 - val_accuracy: 0.9900 - val_loss: 0.0463\n",
            "Epoch 92/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0609 - val_accuracy: 0.9892 - val_loss: 0.0430\n",
            "Epoch 93/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0597 - val_accuracy: 0.9908 - val_loss: 0.0340\n",
            "Epoch 94/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0653 - val_accuracy: 0.9908 - val_loss: 0.0368\n",
            "Epoch 95/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0635 - val_accuracy: 0.9915 - val_loss: 0.0390\n",
            "Epoch 96/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0482 - val_accuracy: 0.9892 - val_loss: 0.0406\n",
            "Epoch 97/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0693 - val_accuracy: 0.9900 - val_loss: 0.0462\n",
            "Epoch 98/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0693 - val_accuracy: 0.9908 - val_loss: 0.0437\n",
            "Epoch 99/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0588 - val_accuracy: 0.9923 - val_loss: 0.0380\n",
            "Epoch 100/100\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0604 - val_accuracy: 0.9908 - val_loss: 0.0392\n",
            "\u001b[1m365/365\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Accuracy en entrenamiento: 99.24%\n",
            "Accuracy en prueba: 99.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_roc = parte1(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "b1f0863879114843be9a6edefb5aad04",
            "c2cd3784c40742769a113fa50f3419a9",
            "0ed91395456a41e2a03038d5aa42468a",
            "b1b89dacb85e4d429485aff8ce653bd2",
            "022172ac05f74ef8ad5a72494d76234e",
            "8198556000ac4f6195109486d194cf48",
            "60e63c46c3494e0b8c90e6a80989382f",
            "3b4254b277e04211ba82c3ce9329b704",
            "c3f41b2b4a5c4ec69f262f1fc6c6dbfd",
            "3a73d2b27af047b49cc5dda4aa6e9e75",
            "2bff280eac3c4ac7987d2cc43e50f1c2"
          ]
        },
        "id": "E41GzD_RZiHV",
        "outputId": "dbb5ea8e-2d8a-448e-f78e-c02a7b69580f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1f0863879114843be9a6edefb5aad04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "=================================\n",
            "| Processor | Package           |\n",
            "---------------------------------\n",
            "| tokenize  | combined          |\n",
            "| mwt       | combined          |\n",
            "| pos       | combined_charlm   |\n",
            "| lemma     | combined_nocharlm |\n",
            "=================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: mwt\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: pos\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: lemma\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Done loading processors!\n",
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy TF-IDF: 63.393958076448826%\n",
            "Accuracy Topic: 47.957768187422936%\n",
            "Accuracy Fast: 87.307336621455%\n",
            "Accuracy BERT: 44.551479654747226%\n",
            "            cluster     topic  topic_tfidf      FAST\n",
            "essay_set                                           \n",
            "1          0.403995  0.762152     0.501929  0.420263\n",
            "2          0.483581  0.419649     0.483715  0.424392\n",
            "3          0.444000  0.917820     0.420133  0.399633\n",
            "4          0.429894  0.447251     0.389553  0.454578\n",
            "5          0.356771  0.440113     0.377772  0.419477\n",
            "6          0.694444  0.467028     0.494721  0.713289\n",
            "7          0.469975  0.597480     0.465716  0.422121\n",
            "8          0.421991  0.659371     0.949413  0.429079\n"
          ]
        }
      ]
    }
  ]
}